#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from argparse import ArgumentParser
from os import path
from tqdm import tqdm
import multiprocessing as multi
from itertools import product
import edlib
from termcolor import colored
from sys import stderr
import tracemalloc
from src.utils import *
from src.classes import *


def main():
    ### DEFINE AND CHECK ARGS
    default_prefix=path.basename(__file__).split(sep='.')[0]
    parser = ArgumentParser(description="Takes a set of ONT-primer prefixes ddRADseq files and a set of barcodes and demultiplexes them.")
    parser.add_argument('-f', '--fastq', help='Path to the input fq file. Required.', type=str, required=True)
    parser.add_argument('-d', '--demux', help='Path to the demux file. Required.', type=str, required=True)
    parser.add_argument('-b', '--buffer', help='The integer number of base pairs outside of the long element the short element can align to. Defaults to 0 (internal matching only).', type=int, default=0)
    parser.add_argument('-t', '--threads', help='The number of threads (actually CPU cores) this script can use to parallelize processes. Defaults to half the capacity of the host machine.', type=int, default=multi.cpu_count() // 2)    
    parser.add_argument('-p', '--prefix', help='Output prefix. Defaults to \'ONTddRADparse_out\' if not set.', default=f'{default_prefix}_out', type=str)
    parser.add_argument('-fa', '--fuzzy_aln_percent', help='The minimum percent identity needed to fuzzy-match a full index to a sequence.', default=.9, type=float)
    parser.add_argument('-ea', '--exact_aln_percent', help='The minimum percent identity needed to exact-match a short index to a sequence.', default=1, type=float)
    parser.add_argument('-mc', '--max_comparisons', help='The maximum number of \'valid\' alignments the program can make in \'fuzzy\' alignments  before picking the best match. Defaults to the number of barcodes in your demux file. Lowering the value increases speed, but may produce misclassifications.', type=int)
    args = parser.parse_args()

    ### COLORS!
    BRIGHT_CYAN = '\033[96m'
    RESET = '\033[0m' # called to return to standard terminal text color

    # Ensure that our alignment percent arguments are a value between 0 and 1
    if not (min(0, 1) < args.fuzzy_aln_percent <= max(0, 1)) or not (min(0, 1) < args.exact_aln_percent <= max(0, 1)):
        raise ValueError(colored('Alignment arguments (-fa, -ea) must be percentages: eg, -fa .9', 'light_red'))
    
    # Once all our args are valid, print the speeddemONT logo in obnoxious rainbow font, and start running
    #print_logo()
    # all 'info' print statements need to be bold
    print_logo()
    print_args(args)


    ### READ IN FILES
    print_user_info('Reading in sequences:')
    SimpleSeqRecord_lst = parse_seqfile(args.fastq) # uses FastqGeneralIterator to read big FAs cheaply
    # we want to chunk up the seq_record_lst into smaller items.

    SampleID_dict = make_SampleID_dict(args.demux, args.fuzzy_aln_percent, args.exact_aln_percent, args.buffer)

    print_user_info('Making alignments:')
    DCA_lst=[]
    chunk_size = 10000 # this is an arbitrary number
    if len(SimpleSeqRecord_lst) > chunk_size:
        print_user_info(f'\tLarge input. Running a burnin of {int(chunk_size/10)} replicates to optimize alignment order', bold=False)
        SampleID_dict=optimize_SampleID_dict_order(SimpleSeqRecord_lst, int(chunk_size/10), SampleID_dict)

    # if the user set args.max_comparisons, use their value
    # otherwise, set to 1 if 'exact', and 'number of DCs' if fuzzy
    if (args.max_comparisons is None):
        if (args.fuzzy_aln_percent == float(1)):
            args.max_comparisons = 1
        else:
            args.max_comparisons = sum(len(SampleID_dict[key][0]) for key in SampleID_dict)

    input_lst = list(product(SimpleSeqRecord_lst, [SampleID_dict], [args.max_comparisons]))
    DCA_lst_valid = []

    print_user_info(f'\tBeginning main loop:', bold=False)
    input_lst_of_lsts = chunk_input_lst(input_lst, chunk_size)
    pool = multi.Pool(processes = args.threads)
    for tranche in tqdm(input_lst_of_lsts):
        DCA_sublst = pool.map(make_DCA, tranche)
        DCA_lst.extend(DCA_sublst)
    pool.close()
    pool.join()

    print_user_info('Checking alignment validity:')
    sample_id_dict, invalid_dict = split_DCA_lst(SampleID_dict, DCA_lst)

    # Begin writing plots and FQs to outdir
    # Create one DemuxxedSample for each unique sample_id

    print_user_info(f'Writing fastq files to {BRIGHT_CYAN}{args.prefix}/reads{RESET}:')
    fq_lst = []
    for SampleID, SampleID_info in SampleID_dict.items():
        DS = DemuxxedSample(SampleID, SampleID_info[1])
        fq_lst.append(DS.init_FastqFile_from_Demuxxed_Sample(outdir=f'{args.prefix}/reads'))


    for fq in fq_lst:
        fq.write_FastqFile_to_outdir()
        #del fq
    #pool = multi.Pool(processes = args.threads/10) # FIXME - please improve the number of threads that can be run by writing without BioPython
    #pool.map(write_fastq, fq_lst)
    #pool.close()
    #pool.join()    


    # Plot results and print percent
    print_user_info(f'\nWriting summary statistics:')
    plot1, df1 = plot_number_of_SimpleSeqRecords_per_SampleID(SampleID_dict)
    plot1.savefig(f'{args.prefix}/{args.prefix}_demult_success.png', dpi=300)
    df1.to_csv(f'{args.prefix}/{args.prefix}_seqs_per_SampleID_stats.tsv', sep = "\t", index=False)
    print_demultiplexing_summary(df1)


    plot2, df2 = plot_reasons_for_SimpleSeqRecord_invalidity(invalid_dict)
    plot2.savefig(f'{args.prefix}/{args.prefix}_demult_failure.png', dpi=300)
    df2.to_csv(f'{args.prefix}/{args.prefix}_failed_seqs_stats.tsv', sep = "\t", index=False)

# If this is being imported
if __name__=="__main__":
    main()